{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE FOR REBECCA:**\n",
    "\n",
    "This notebook just represents the modelling section. This should be a part of the final notebook and doesn't run on its own. Have not included any library imports, preprocessing steps, code output etc. This is just to indicate the report text and where in the notebook it goes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that this is an image classification task, the natural direction to take is some kind of CNN which is the standard model for computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN trained from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simple CNN trained from scratch as a baseline in order to determine how well we can do using a basic technique and then try methods to improve upon this baseline performance.\n",
    "\n",
    "We use a model with 4 convolutional layers interspersed with maxpooling layers. We have added a dropout layer in order to curb overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build and compile our simple CNN model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name = 'Simple_CNN')\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', input_shape=(300, 400, 1)))\n",
    "model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "        data_train_augmented,\n",
    "        y_train_augmented,\n",
    "        epochs=6,\n",
    "        batch_size = 16, \n",
    "        validation_data=(data_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model reaches ~80% validation accuracy and takes <5 minutes to train on a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing training history:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After epoch 5, the model starts to overfit, as can be seen by the training history plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot training and test ROCs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics for Testing Data\n",
    "probs_test = model.predict(data_val)\n",
    "preds_test = probs_test.reshape(-1)\n",
    "fpr_test, tpr_test, threshold_test = metrics.roc_curve(y_val, preds_test)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "#Metrics for Training Data\n",
    "probs_train = model.predict(data_train)\n",
    "preds_train = probs_train.reshape(-1)\n",
    "fpr_train, tpr_train, threshold_train = metrics.roc_curve(y_train, preds_train)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "\n",
    "#Plot\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_test, tpr_test, 'b', label = 'Test AUC = %0.2f' % roc_auc_test)\n",
    "plt.plot(fpr_train, tpr_train, 'g', label = 'Train AUC = %0.2f' % roc_auc_train)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show();\n",
    "\n",
    "#Training and Test AUCs\n",
    "print('Test AUC = %0.4f' % roc_auc_test)\n",
    "print('Train AUC = %0.4f' % roc_auc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the AUC we can see that we have pretty good performance. \n",
    "\n",
    "Naturally, we want to further investigate this to visualise what features our model is picking up on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert visualization code and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning using a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after augmentation, our dataset is relatively small in size. This, along with our limits on compute and time indicate that we should use a pretrained model to build on top of. One of the major advantages of doing this is that we let the pretrained model use all the low level features it has already learnt and build and train on top of this so these features can be adapted and used for our task. The learning of features such as basic lines and shapes is common to both tasks even though the datasets are not quite similar.\n",
    "\n",
    "[VGG](https://www.robots.ox.ac.uk/~vgg/research/very_deep/) is a standard pretrained model trained on [ImageNet](http://www.image-net.org/) data. It has been built into Keras and can be loaded and used easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(300, 400, 1))\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Concatenate()([img_input, img_input, img_input]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
