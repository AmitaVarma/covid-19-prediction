{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot\n",
    "import matplotlib.pylab as plt \n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation, Reshape\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data\n",
    "\n",
    "data = []\n",
    "file_list = []\n",
    "y = []\n",
    "\n",
    "for png in os.listdir(\"../data/CT_COVID\"):\n",
    "    pic = plt.imread(\"../data/CT_COVID/\" + png, 0)\n",
    "    data.append(pic)\n",
    "    file_list.append(png)\n",
    "    y.append(1)\n",
    "\n",
    "for png in os.listdir(\"../data/CT_NonCOVID\"):\n",
    "    pic = plt.imread(\"../data/CT_NonCOVID/\" + png, 0)\n",
    "    data.append(pic)\n",
    "    file_list.append(png)\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_excel(\"../data/COVID-CT-MetaInfo.xlsx\", header = None, names = ['file','patient','column3','note'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dim = (300, 400) #use the averages for the dimensions\n",
    "\n",
    "data_cleaned = []\n",
    "\n",
    "for img in data:\n",
    "    #First, take the mean of the 3rd dimension (channels) if it exists\n",
    "    if len(img.shape) == 3:\n",
    "        img = np.mean(img, axis = 2)\n",
    "    \n",
    "    #Using PIL Image processor, resize using high quality down-sampling filter \n",
    "    img = Image.fromarray(img)\n",
    "    img = img.resize((image_dim[1], image_dim[0]), Image.ANTIALIAS)\n",
    "    img = np.array(img)\n",
    "    \n",
    "    #Normalize image values\n",
    "    img = img/255\n",
    "    \n",
    "    data_cleaned.append(img)\n",
    "\n",
    "data_cleaned = np.array(data_cleaned)\n",
    "data_cleaned = np.expand_dims(data_cleaned,axis = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train, data_val, y_train, y_val = train_test_split(data_cleaned, np.array(y),\\\n",
    "                                                        train_size = 0.75, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flip horizontally\n",
    "horiz_flip = tf.image.flip_left_right(data_train) \n",
    "#Flip vertically\n",
    "vert_flip = tf.image.flip_up_down(data_train)\n",
    "\n",
    "data_train_augmented = np.concatenate((data_train, horiz_flip, vert_flip), axis = 0)\n",
    "y_train_augmented = np.concatenate((y_train,y_train,y_train), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# load VGG and concatenate input images into 3 channels because vgg takes rgb images\n",
    "img_input = Input(shape=(300, 400, 1))\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Concatenate()([img_input, img_input, img_input]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VGG_Pretrain\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 300, 400, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 300, 400, 3)  0           input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 300, 400, 64) 1792        concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 300, 400, 64) 36928       block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_pool (MaxPooling2D)      (None, 150, 200, 64) 0           block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv1 (Conv2D)           (None, 150, 200, 128 73856       block1_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2_conv2 (Conv2D)           (None, 150, 200, 128 147584      block2_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 75, 100, 128) 0           block2_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv1 (Conv2D)           (None, 75, 100, 256) 295168      block2_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv2 (Conv2D)           (None, 75, 100, 256) 590080      block3_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_conv3 (Conv2D)           (None, 75, 100, 256) 590080      block3_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 50, 256)  0           block3_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv1 (Conv2D)           (None, 37, 50, 512)  1180160     block3_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv2 (Conv2D)           (None, 37, 50, 512)  2359808     block4_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_conv3 (Conv2D)           (None, 37, 50, 512)  2359808     block4_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 18, 25, 512)  0           block4_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv1 (Conv2D)           (None, 18, 25, 512)  2359808     block4_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv2 (Conv2D)           (None, 18, 25, 512)  2359808     block5_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_conv3 (Conv2D)           (None, 18, 25, 512)  2359808     block5_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block5_pool (MaxPooling2D)      (None, 9, 12, 512)   0           block5_conv3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 512)          0           block5_pool[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 2)            1026        global_average_pooling2d_13[0][0]\n",
      "==================================================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 7,080,450\n",
      "Non-trainable params: 7,635,264\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# add a global spatial average pooling layer and a dense layer to classify 2 classes\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# new model to train\n",
    "new_model = Model(inputs=model.input, outputs=predictions, name = \"VGG_Pretrain\")\n",
    "\n",
    "# freeze many convolutional VGG layers: only train the last block\n",
    "for layer in model.layers[:16]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[17:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1677 samples, validate on 187 samples\n",
      "Epoch 1/5\n",
      "1677/1677 [==============================] - 45s 27ms/sample - loss: 0.4664 - accuracy: 0.8050 - val_loss: 0.4146 - val_accuracy: 0.8235\n",
      "Epoch 2/5\n",
      "1677/1677 [==============================] - 44s 26ms/sample - loss: 0.3195 - accuracy: 0.8640 - val_loss: 0.3825 - val_accuracy: 0.8396\n",
      "Epoch 3/5\n",
      "1677/1677 [==============================] - 44s 26ms/sample - loss: 0.3126 - accuracy: 0.8652 - val_loss: 0.4072 - val_accuracy: 0.8449\n",
      "Epoch 4/5\n",
      "1677/1677 [==============================] - 44s 26ms/sample - loss: 0.2930 - accuracy: 0.8754 - val_loss: 0.3891 - val_accuracy: 0.8021\n",
      "Epoch 5/5\n",
      "1677/1677 [==============================] - 43s 26ms/sample - loss: 0.2823 - accuracy: 0.8795 - val_loss: 0.3730 - val_accuracy: 0.8396\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=5e-4)\n",
    "new_model.compile(optimizer=sgd, loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "history = new_model.fit(\n",
    "        data_train_augmented,\n",
    "        tf.keras.utils.to_categorical(y_train_augmented),\n",
    "        epochs=5,\n",
    "        batch_size = 16, \n",
    "        validation_data=(data_val, tf.keras.utils.to_categorical(y_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save weights\n",
    "model.save_weights('models/VGG_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load weights\n",
    "model.load_weights('models/VGG_model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
