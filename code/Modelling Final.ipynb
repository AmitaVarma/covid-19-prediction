{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE FOR REBECCA:**\n",
    "\n",
    "This notebook just represents the modelling section. This should be a part of the final notebook and doesn't run on its own. Have not included any library imports, preprocessing steps, code output etc. This is just to indicate the report text and where in the notebook it goes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that this is an image classification task, the natural direction to take is some kind of CNN which is the standard model for computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN trained from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a simple CNN trained from scratch as a baseline in order to determine how well we can do using a basic technique and then try methods to improve upon this baseline performance.\n",
    "\n",
    "We use a model with 4 convolutional layers interspersed with maxpooling layers. We have added a dropout layer in order to curb overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build and compile our simple CNN model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(name = 'Simple_CNN')\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same', input_shape=(300, 400, 1)))\n",
    "model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D((2, 2), padding = 'same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding = 'same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.05))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fit the model:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "        data_train_augmented,\n",
    "        y_train_augmented,\n",
    "        epochs=6,\n",
    "        batch_size = 16, \n",
    "        validation_data=(data_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the model reaches ~80% validation accuracy and takes <5 minutes to train on a GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing training history:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After epoch 5, the model starts to overfit, as can be seen by the training history plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot training and test ROCs:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Metrics for Testing Data\n",
    "probs_test = model.predict(data_val)\n",
    "preds_test = probs_test.reshape(-1)\n",
    "fpr_test, tpr_test, threshold_test = metrics.roc_curve(y_val, preds_test)\n",
    "roc_auc_test = metrics.auc(fpr_test, tpr_test)\n",
    "\n",
    "#Metrics for Training Data\n",
    "probs_train = model.predict(data_train)\n",
    "preds_train = probs_train.reshape(-1)\n",
    "fpr_train, tpr_train, threshold_train = metrics.roc_curve(y_train, preds_train)\n",
    "roc_auc_train = metrics.auc(fpr_train, tpr_train)\n",
    "\n",
    "#Plot\n",
    "plt.title('ROC Curve')\n",
    "plt.plot(fpr_test, tpr_test, 'b', label = 'Test AUC = %0.2f' % roc_auc_test)\n",
    "plt.plot(fpr_train, tpr_train, 'g', label = 'Train AUC = %0.2f' % roc_auc_train)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show();\n",
    "\n",
    "#Training and Test AUCs\n",
    "print('Test AUC = %0.4f' % roc_auc_test)\n",
    "print('Train AUC = %0.4f' % roc_auc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the AUC we can see that we have pretty good performance. \n",
    "\n",
    "Naturally, we want to further investigate this to visualise what features our model is picking up on. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizations:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# insert visualization code and analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning using a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even after augmentation, our dataset is relatively small in size. This, along with our limits on compute and time indicate that we should use a pretrained model to build on top of. One of the major advantages of doing this is that we let the pretrained model use all the low level features it has already learnt and build and train on top of this so these features can be adapted and used for our task. The learning of features such as basic lines and shapes is common to both tasks even though the datasets are not quite similar.\n",
    "\n",
    "[VGG](https://www.robots.ox.ac.uk/~vgg/research/very_deep/) is a standard pretrained model trained on [ImageNet](http://www.image-net.org/) data. It has been built into Keras and can be loaded and used easily. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load VGG and concatenate input images into 3 channels:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_input = Input(shape=(300, 400, 1))\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_tensor=Concatenate()([img_input, img_input, img_input]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGG takes RGB images (3 channels) and our images are greyscale (1 channel). Hence, we replicate our channel thrice to create an image of the correct shape.\n",
    "Additionally, we use `include_top=False` to only include the main convolutional layers of the model and not the input layers and final classification layers. This is required so we can modify the model according to our task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add required final layers and freeze convolutional layers:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a pooling layer and a final classification layer to classify into two classes. This along with the VGG convolutional blocks are combined into a new model. We freeze all the convolutional blocks but the last. This is done so that the higher level features can adapt to our new dataset without retraining the low level features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a global spatial average pooling layer and a dense layer to classify 2 classes\n",
    "x = model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "\n",
    "# new model to train\n",
    "new_model = Model(inputs=model.input, outputs=predictions, name = \"VGG_Pretrain\")\n",
    "\n",
    "# freeze many convolutional VGG layers: only train the last block\n",
    "for layer in model.layers[:16]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[17:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compile and train the model:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a small learning rate so that the model does not unlearn the features it learnt from the previous frozen layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = SGD(lr=5e-4)\n",
    "new_model.compile(optimizer=sgd, loss=tf.keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "history = new_model.fit(\n",
    "        data_train_augmented,\n",
    "        tf.keras.utils.to_categorical(y_train_augmented),\n",
    "        epochs=5,\n",
    "        batch_size = 16, \n",
    "        validation_data=(data_val, tf.keras.utils.to_categorical(y_val)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
